{
    "sourceFile": "src/ImportanceSampling.jl",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 43,
            "patches": [
                {
                    "date": 1626309654641,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1626309931115,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,26 +56,26 @@\n     # Reshape to matrix (easier to deal with)\n     log_ratios = reshape(log_ratios, data_size, post_sample_size)\n     weights::AbstractArray{F} = similar(log_ratios)\n     # Shift ratios by maximum to prevent overflow\n-    @tturbo warn_check_args=true  @. weights = exp(log_ratios - $maximum(log_ratios; dims=2))\n+    @tturbo @. weights = exp(log_ratios - $maximum(log_ratios; dims=2))\n \n     r_eff = _generate_r_eff(weights, dims, r_eff, source)\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @tturbo warn_check_args=true  @. tail_length = def_tail_length(post_sample_size, r_eff)\n-    @tturbo warn_check_args=true  @. ξ = ParetoSmooth.do_psis_i!($eachrow(weights), tail_length)\n+    @tturbo @. tail_length = def_tail_length(post_sample_size, r_eff)\n+    @tturbo @. ξ = ParetoSmooth.do_psis_i!($eachrow(weights), tail_length)\n \n     @tullio norm_const[i] := weights[i, j]\n-    @tturbo warn_check_args=true  @. weights /= norm_const\n+    @tturbo @. weights /= norm_const\n     ess = psis_n_eff(weights, r_eff)\n \n     weights = reshape(weights, dims)\n \n     if log_weights\n-        @tturbo warn_check_args=true  @. weights = log(weights)\n+        @tturbo @. weights = log(weights)\n     end\n \n     if any(ξ .≥ .7)\n         @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n"
                },
                {
                    "date": 1626310423981,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,10 +63,12 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @tturbo @. tail_length = def_tail_length(post_sample_size, r_eff)\n-    @tturbo @. ξ = ParetoSmooth.do_psis_i!($eachrow(weights), tail_length)\n+    @batch for i in eachindex()\n+        tail_length[i] = def_tail_length(post_sample_size, r_eff)\n+        ξ = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n+    end\n \n     @tullio norm_const[i] := weights[i, j]\n     @tturbo @. weights /= norm_const\n     ess = psis_n_eff(weights, r_eff)\n"
                },
                {
                    "date": 1626310442183,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @batch for i in eachindex()\n+    @batch for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff)\n         ξ = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n     end\n \n"
                },
                {
                    "date": 1626310464203,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,6 @@\n using LoopVectorization\n+using Polyester\n using Tullio\n \n const LIKELY_ERROR_CAUSES = \"\"\"\n 1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n"
                },
                {
                    "date": 1626310530559,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n     @batch for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff)\n-        ξ = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n+        ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n     end\n \n     @tullio norm_const[i] := weights[i, j]\n     @tturbo @. weights /= norm_const\n"
                },
                {
                    "date": 1626310728081,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,9 +64,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @batch for i in 1:data_size\n+    @inbounds @simd Threads.@threads for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff)\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n     end\n \n"
                },
                {
                    "date": 1626310848143,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,8 @@\n using LoopVectorization\n using Polyester\n using Tullio\n+using VectorizationBase\n \n const LIKELY_ERROR_CAUSES = \"\"\"\n 1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n 2. Your chains failed to converge. Check your diagnostics. \n@@ -67,12 +68,11 @@\n     ξ = similar(log_ratios, data_size)\n     @inbounds @simd Threads.@threads for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff)\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n+        weights[i,:] /= VectorizationBase.vsum(weights[i, :])\n     end\n-\n-    @tullio norm_const[i] := weights[i, j]\n-    @tturbo @. weights /= norm_const\n+    \n     ess = psis_n_eff(weights, r_eff)\n \n     weights = reshape(weights, dims)\n \n"
                },
                {
                    "date": 1626310985421,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds @simd Threads.@threads for i in 1:data_size\n+    Threads.@threads @inbounds @simd for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff)\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= VectorizationBase.vsum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626311027810,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    Threads.@threads @inbounds @simd for i in 1:data_size\n+    Threads.@threads @inbounds for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff)\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= VectorizationBase.vsum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626311046687,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    Threads.@threads @inbounds for i in 1:data_size\n+    @inbounds Threads.@threads for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff)\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= VectorizationBase.vsum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626311085341,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n     @inbounds Threads.@threads for i in 1:data_size\n-        tail_length[i] = def_tail_length(post_sample_size, r_eff)\n+        tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= VectorizationBase.vsum(weights[i, :])\n     end\n     \n"
                },
                {
                    "date": 1626311138979,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     ξ = similar(log_ratios, data_size)\n     @inbounds Threads.@threads for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n-        weights[i,:] /= VectorizationBase.vsum(weights[i, :])\n+        weights[i,:] /= sum(weights[i, :])\n     end\n     \n     ess = psis_n_eff(weights, r_eff)\n \n"
                },
                {
                    "date": 1626312336106,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds Threads.@threads for i in 1:data_size\n+    @inbounds for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626312466811,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds for i in 1:data_size\n+    @inbounds Threads.@threads for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626312599061,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds Threads.@threads for i in 1:data_size\n+    @floop ThreadedEx() for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626312634205,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n+using FLoops\n using LoopVectorization\n using Polyester\n using Tullio\n-using VectorizationBase\n \n const LIKELY_ERROR_CAUSES = \"\"\"\n 1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n 2. Your chains failed to converge. Check your diagnostics. \n"
                },
                {
                    "date": 1626312852704,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @floop ThreadedEx() for i in 1:data_size\n+    @floop WorkStealingEx() for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n@@ -143,9 +143,9 @@\n \n     # truncate at max of raw weights (1 after scaling)\n     clamp!(sorted_ratios, 0, 1)\n     # unsort the ratios to their original position:\n-    is_ratios .= @views sorted_ratios[invperm(ordering)]\n+    @turbo is_ratios .= @views sorted_ratios[invperm(ordering)]\n \n     return ξ::T\n end\n \n"
                },
                {
                    "date": 1626313259741,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,6 @@\n using FLoops\n+using FoldsThreads\n using LoopVectorization\n using Polyester\n using Tullio\n \n@@ -65,11 +66,11 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @floop WorkStealingEx() for i in 1:data_size\n+    @floop WorkStealingEx for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n-        ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n+        ξ[i] = ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n     \n     ess = psis_n_eff(weights, r_eff)\n"
                },
                {
                    "date": 1626313294230,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -59,9 +59,9 @@\n     # Reshape to matrix (easier to deal with)\n     log_ratios = reshape(log_ratios, data_size, post_sample_size)\n     weights::AbstractArray{F} = similar(log_ratios)\n     # Shift ratios by maximum to prevent overflow\n-    @tturbo @. weights = exp(log_ratios - $maximum(log_ratios; dims=2))\n+    @. weights = exp(log_ratios - $maximum(log_ratios; dims=2))\n \n     r_eff = _generate_r_eff(weights, dims, r_eff, source)\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n"
                },
                {
                    "date": 1626313667370,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,8 @@\n-using FLoops\n-using FoldsThreads\n using LoopVectorization\n using Polyester\n using Tullio\n+using VectorizationBase\n \n const LIKELY_ERROR_CAUSES = \"\"\"\n 1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n 2. Your chains failed to converge. Check your diagnostics. \n@@ -59,18 +58,18 @@\n     # Reshape to matrix (easier to deal with)\n     log_ratios = reshape(log_ratios, data_size, post_sample_size)\n     weights::AbstractArray{F} = similar(log_ratios)\n     # Shift ratios by maximum to prevent overflow\n-    @. weights = exp(log_ratios - $maximum(log_ratios; dims=2))\n+    @tturbo @. weights = exp(log_ratios - $maximum(log_ratios; dims=2))\n \n     r_eff = _generate_r_eff(weights, dims, r_eff, source)\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @floop WorkStealingEx for i in 1:data_size\n+    @inbounds Threads.@threads for i in 1:data_size\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n-        ξ[i] = ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n+        ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n     \n     ess = psis_n_eff(weights, r_eff)\n@@ -144,9 +143,9 @@\n \n     # truncate at max of raw weights (1 after scaling)\n     clamp!(sorted_ratios, 0, 1)\n     # unsort the ratios to their original position:\n-    @turbo is_ratios .= @views sorted_ratios[invperm(ordering)]\n+    is_ratios .= @views sorted_ratios[invperm(ordering)]\n \n     return ξ::T\n end\n \n"
                },
                {
                    "date": 1626314145531,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,7 @@\n using LoopVectorization\n using Polyester\n using Tullio\n-using VectorizationBase\n \n const LIKELY_ERROR_CAUSES = \"\"\"\n 1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n 2. Your chains failed to converge. Check your diagnostics. \n"
                },
                {
                    "date": 1626314273071,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,9 +64,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds Threads.@threads for i in 1:data_size\n+    @inbounds @batch per=thread for i in eachindex(tail_length)\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626314409915,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,10 @@\n using LoopVectorization\n using Polyester\n+using TensorOperations\n using Tullio\n \n+\n const LIKELY_ERROR_CAUSES = \"\"\"\n 1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n 2. Your chains failed to converge. Check your diagnostics. \n 3. You do not have enough posterior samples (Less than ~100 samples) -- try sampling more values.\n"
                },
                {
                    "date": 1626362753719,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,6 @@\n using LoopVectorization\n using Polyester\n-using TensorOperations\n using Tullio\n \n \n const LIKELY_ERROR_CAUSES = \"\"\"\n"
                },
                {
                    "date": 1626362835646,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds @batch per=thread for i in eachindex(tail_length)\n+    @inbounds for i in eachindex(tail_length)\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626362886466,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds for i in eachindex(tail_length)\n+    @inbounds @batch per=thread for i in eachindex(tail_length)\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n         weights[i,:] /= sum(weights[i, :])\n     end\n"
                },
                {
                    "date": 1626362946172,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,11 +68,11 @@\n     ξ = similar(log_ratios, data_size)\n     @inbounds @batch per=thread for i in eachindex(tail_length)\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n-        weights[i,:] /= sum(weights[i, :])\n     end\n     \n+    weights[i,:] /= sum(weights[i, :])\n     ess = psis_n_eff(weights, r_eff)\n \n     weights = reshape(weights, dims)\n \n"
                },
                {
                    "date": 1626363052485,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -70,9 +70,10 @@\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n     end\n     \n-    weights[i,:] /= sum(weights[i, :])\n+    @tullio norm_const[i] := weights[i, j]\n+    weights .= weights ./ norm_const\n     ess = psis_n_eff(weights, r_eff)\n \n     weights = reshape(weights, dims)\n \n"
                },
                {
                    "date": 1626363167417,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds @batch per=thread for i in eachindex(tail_length)\n+    @inbounds for i in eachindex(tail_length)\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n     end\n     \n"
                },
                {
                    "date": 1626363225772,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds for i in eachindex(tail_length)\n+    @inbounds Threads.@threads for i in eachindex(tail_length)\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n     end\n     \n"
                },
                {
                    "date": 1626363361308,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds Threads.@threads for i in eachindex(tail_length)\n+    @inbounds @batch per=thread for i in eachindex(tail_length)\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n     end\n     \n"
                },
                {
                    "date": 1626363453857,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n-    @inbounds @batch per=thread for i in eachindex(tail_length)\n+    @inbounds Threads.@threads for i in eachindex(tail_length)\n         tail_length[i] = def_tail_length(post_sample_size, r_eff[i])\n         ξ[i] = @views ParetoSmooth.do_psis_i!(weights[i,:], tail_length[i])\n     end\n     \n"
                },
                {
                    "date": 1626452759502,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,5 @@\n using LoopVectorization\n-using Polyester\n using Tullio\n \n \n const LIKELY_ERROR_CAUSES = \"\"\"\n"
                },
                {
                    "date": 1626453064337,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,9 @@\n end\n \n \n \"\"\"\n-    do_psis_i!(is_ratios::AbstractVector{AbstractFloat}, tail_length::Integer)::T\n+    do_psis_i!(is_ratios::AbstractVector{AbstractFloat}, tail_length::Integer) -> T\n \n Do PSIS on a single vector, smoothing its tail values.\n \n # Arguments\n"
                },
                {
                    "date": 1626453089719,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -242,8 +242,9 @@\n         return r_eff\n     end\n end\n \n+\n \"\"\"\n Make sure all inputs to `psis` are valid.\n \"\"\"\n function check_input_validity_psis(\n@@ -266,8 +267,9 @@\n     end\n     return nothing\n end\n \n+\n \"\"\"\n Check the tail to make sure a GPD fit is possible.\n \"\"\"\n function check_tail(tail::AbstractVector{T}) where {T<:AbstractFloat}\n"
                },
                {
                    "date": 1626454092733,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,9 +71,9 @@\n     end\n     \n     @tullio norm_const[i] := weights[i, j]\n     weights .= weights ./ norm_const\n-    ess = psis_n_eff(weights, r_eff)\n+    ess = psis_ess(weights, r_eff)\n \n     weights = reshape(weights, dims)\n \n     if log_weights\n"
                },
                {
                    "date": 1626458228667,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,9 +60,9 @@\n     # Shift ratios by maximum to prevent overflow\n     @tturbo @. weights = exp(log_ratios - $maximum(log_ratios; dims=2))\n \n     r_eff = _generate_r_eff(weights, dims, r_eff, source)\n-    check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n+    _check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n \n     tail_length = similar(log_ratios, Int, data_size)\n     ξ = similar(log_ratios, data_size)\n     @inbounds Threads.@threads for i in eachindex(tail_length)\n@@ -134,9 +134,9 @@\n \n     # Define and check tail\n     tail_start = len - tail_length + 1  # index of smallest tail value\n     @views tail = sorted_ratios[tail_start:len]\n-    check_tail(tail)\n+    _check_tail(tail)\n \n     # Get value just before the tail starts:\n     cutoff = sorted_ratios[tail_start - 1]\n     ξ = psis_smooth_tail!(tail, cutoff)\n@@ -246,9 +246,9 @@\n \n \"\"\"\n Make sure all inputs to `psis` are valid.\n \"\"\"\n-function check_input_validity_psis(\n+function _check_input_validity_psis(\n     log_ratios::AbstractArray{T,3}, r_eff::AbstractVector{T}\n ) where {T<:AbstractFloat}\n     if any(isnan, log_ratios)\n         throw(DomainError(\"Invalid input for `log_ratios` (contains NaN values).\"))\n@@ -271,9 +271,9 @@\n \n \"\"\"\n Check the tail to make sure a GPD fit is possible.\n \"\"\"\n-function check_tail(tail::AbstractVector{T}) where {T<:AbstractFloat}\n+function _check_tail(tail::AbstractVector{T}) where {T<:AbstractFloat}\n     if maximum(tail) ≈ minimum(tail)\n         throw(\n             ArgumentError(\n                 \"Unable to fit generalized Pareto distribution: all tail values are the\" *\n"
                },
                {
                    "date": 1626484622160,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -242,9 +242,9 @@\n         return r_eff\n     end\n end\n \n-\n+    \n \"\"\"\n Make sure all inputs to `psis` are valid.\n \"\"\"\n function _check_input_validity_psis(\n"
                },
                {
                    "date": 1626484665188,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,11 +4,11 @@\n \n const LIKELY_ERROR_CAUSES = \"\"\"\n 1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n 2. Your chains failed to converge. Check your diagnostics. \n-3. You do not have enough posterior samples (Less than ~100 samples) -- try sampling more values.\n+3. You do not have enough posterior samples (ESS < ~100).\n \"\"\"\n-const MIN_TAIL_LEN = 16  # Minimum size of a tail for PSIS to give sensible answers\n+const MIN_TAIL_LEN = 10  # Minimum size of a tail for PSIS to give sensible answers\n const SAMPLE_SOURCES = [\"mcmc\", \"vi\", \"other\"]\n \n export Psis, psis\n \n@@ -251,9 +251,9 @@\n     log_ratios::AbstractArray{T,3}, r_eff::AbstractVector{T}\n ) where {T<:AbstractFloat}\n     if any(isnan, log_ratios)\n         throw(DomainError(\"Invalid input for `log_ratios` (contains NaN values).\"))\n-    elseif any(isinf, log_ratios)\n+    elseif any(isinf, log_rati    os)\n         throw(DomainError(\"Invalid input for `log_ratios` (contains infinite values).\"))\n     elseif isempty(log_ratios)\n         throw(ArgumentError(\"Invalid input for `log_ratios` (array is empty).\"))\n     elseif any(isnan, r_eff)\n"
                },
                {
                    "date": 1626484737810,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,9 +6,9 @@\n 1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n 2. Your chains failed to converge. Check your diagnostics. \n 3. You do not have enough posterior samples (ESS < ~100).\n \"\"\"\n-const MIN_TAIL_LEN = 10  # Minimum size of a tail for PSIS to give sensible answers\n+const MIN_TAIL_LEN = 5  # Minimum size of a tail for PSIS to give sensible answers\n const SAMPLE_SOURCES = [\"mcmc\", \"vi\", \"other\"]\n \n export Psis, psis\n \n@@ -251,9 +251,9 @@\n     log_ratios::AbstractArray{T,3}, r_eff::AbstractVector{T}\n ) where {T<:AbstractFloat}\n     if any(isnan, log_ratios)\n         throw(DomainError(\"Invalid input for `log_ratios` (contains NaN values).\"))\n-    elseif any(isinf, log_rati    os)\n+    elseif any(isinf, log_ratios)\n         throw(DomainError(\"Invalid input for `log_ratios` (contains infinite values).\"))\n     elseif isempty(log_ratios)\n         throw(ArgumentError(\"Invalid input for `log_ratios` (array is empty).\"))\n     elseif any(isnan, r_eff)\n"
                },
                {
                    "date": 1626484881897,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -292,9 +292,9 @@\n end\n \n \n \"\"\"\n-Assume that all objects belong to a single chain if chain index is missing. Warn user.\n+Assume that all objects belong to a single chain if chain index is missing. Inform user.\n \"\"\"\n function _assume_one_chain(log_ratios)\n     @info \"Chain information was not provided; \" *\n           \"all samples are assumed to be drawn from a single chain.\"\n"
                },
                {
                    "date": 1626486225465,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -81,10 +81,10 @@\n     end\n \n     if any(ξ .≥ .7)\n         @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n-        \"failed to approximate the true distribution for these points. Treat them \" *\n-        \"with caution.\"\n+        \"failed to approximate the true distribution for these points. Treat these \" *\n+        \"estimates with caution.\"\n     elseif any(ξ .≥ .5)\n         @info \"Some Pareto k values are slightly high (>0.5); convergence may be slow \" *\n         \"and MCSE estimates may be slight underestimates.\"\n     end\n"
                },
                {
                    "date": 1626486967591,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,9 +17,9 @@\n         log_ratios::AbstractArray{T:>AbstractFloat}, \n         r_eff; \n         source::String=\"mcmc\", \n         log_weights::Bool=false\n-        ) -> Psis\n+    ) -> Psis\n \n Implements Pareto-smoothed importance sampling (PSIS).\n \n # Arguments\n"
                }
            ],
            "date": 1626309654640,
            "name": "Commit-0",
            "content": "using LoopVectorization\nusing Tullio\n\nconst LIKELY_ERROR_CAUSES = \"\"\"\n1. Bugs in the program that generated the sample, or otherwise incorrect input variables. \n2. Your chains failed to converge. Check your diagnostics. \n3. You do not have enough posterior samples (Less than ~100 samples) -- try sampling more values.\n\"\"\"\nconst MIN_TAIL_LEN = 16  # Minimum size of a tail for PSIS to give sensible answers\nconst SAMPLE_SOURCES = [\"mcmc\", \"vi\", \"other\"]\n\nexport Psis, psis\n\n\"\"\"\n    psis(\n        log_ratios::AbstractArray{T:>AbstractFloat}, \n        r_eff; \n        source::String=\"mcmc\", \n        log_weights::Bool=false\n        ) -> Psis\n\nImplements Pareto-smoothed importance sampling (PSIS).\n\n# Arguments\n## Positional Arguments\n- `log_ratios::AbstractArray{T}`: An array of importance ratios on the log scale (for \nPSIS-LOO these are *negative* log-likelihood values). Indices must be ordered as \n`[data, draw, chain]`: `log_ratios[1, 2, 3]` should be the log-likelihood of the first data \npoint, evaluated at the second iteration of the third chain. Chain indices can be left off \nif there is only a single chain, or if keyword argument `chain_index` is provided.\n- `r_eff::AbstractArray{T}`: An (optional) vector of relative effective sample sizes used \nin ESS calculations. If left empty, calculated automatically using the FFTESS method \nfrom InferenceDiagnostics.jl. See `relative_eff` to calculate these values. \n\n## Keyword Arguments\n\n- `chain_index::Vector{Integer}`: An (optional) vector of integers indicating which chain \neach sample belongs to.\n- `source::String=\"mcmc\"`: A string or symbol describing the source of the sample being \nused. If `\"mcmc\"`, adjusts ESS for autocorrelation. Otherwise, samples are assumed to be \nindependent. Currently permitted values are $SAMPLE_SOURCES.\n- `log_weights::Bool=false`: Return log weights, rather than the PSIS weights. \n\"\"\"\nfunction psis(\n    log_ratios::T,\n    r_eff::AbstractArray{F}=similar(log_ratios, 0);\n    source::Union{AbstractString,Symbol}=\"mcmc\",\n    log_weights::Bool=false,\n) where {F<:AbstractFloat,T<:AbstractArray{F,3}}\n    source = lowercase(String(source))\n    dims = size(log_ratios)\n\n    data_size = dims[1]\n    post_sample_size = dims[2] * dims[3]\n\n    # Reshape to matrix (easier to deal with)\n    log_ratios = reshape(log_ratios, data_size, post_sample_size)\n    weights::AbstractArray{F} = similar(log_ratios)\n    # Shift ratios by maximum to prevent overflow\n    @tturbo warn_check_args=true  @. weights = exp(log_ratios - $maximum(log_ratios; dims=2))\n\n    r_eff = _generate_r_eff(weights, dims, r_eff, source)\n    check_input_validity_psis(reshape(log_ratios, dims), r_eff)\n\n    tail_length = similar(log_ratios, Int, data_size)\n    ξ = similar(log_ratios, data_size)\n    @tturbo warn_check_args=true  @. tail_length = def_tail_length(post_sample_size, r_eff)\n    @tturbo warn_check_args=true  @. ξ = ParetoSmooth.do_psis_i!($eachrow(weights), tail_length)\n\n    @tullio norm_const[i] := weights[i, j]\n    @tturbo warn_check_args=true  @. weights /= norm_const\n    ess = psis_n_eff(weights, r_eff)\n\n    weights = reshape(weights, dims)\n\n    if log_weights\n        @tturbo warn_check_args=true  @. weights = log(weights)\n    end\n\n    if any(ξ .≥ .7)\n        @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n        \"failed to approximate the true distribution for these points. Treat them \" *\n        \"with caution.\"\n    elseif any(ξ .≥ .5)\n        @info \"Some Pareto k values are slightly high (>0.5); convergence may be slow \" *\n        \"and MCSE estimates may be slight underestimates.\"\n    end\n\n    return Psis(weights, ξ, ess, r_eff, tail_length, post_sample_size, data_size)\nend\n\n\nfunction psis(\n    log_ratios::AbstractMatrix{T},\n    r_eff::AbstractVector{T}=similar(log_ratios, 0);\n    chain_index::AbstractVector{I}=_assume_one_chain(log_ratios),\n    kwargs...,\n) where {T<:AbstractFloat,I<:Integer}\n    \n    new_log_ratios = _convert_to_array(log_ratios, chain_index)\n    return psis(new_log_ratios, r_eff; kwargs...)\nend\n\n\n\"\"\"\n    do_psis_i!(is_ratios::AbstractVector{AbstractFloat}, tail_length::Integer)::T\n\nDo PSIS on a single vector, smoothing its tail values.\n\n# Arguments\n\n- `is_ratios::AbstractVector{AbstractFloat}`: A vector of importance sampling ratios, \nscaled to have a maximum of 1.\n\n# Returns\n\n- `T<:AbstractFloat`: ξ, the shape parameter for the GPD; big numbers indicate thick tails.\n\n# Extended help\n\nAdditional information can be found in the LOO package from R.\n\"\"\"\nfunction do_psis_i!(\n    is_ratios::AbstractVector{T}, tail_length::Integer\n) where {T<:AbstractFloat}\n    len = length(is_ratios)\n\n    # sort is_ratios and also get results of sortperm() at the same time\n    ordering = sortperm(is_ratios; alg=QuickSort)\n    sorted_ratios = is_ratios[ordering]\n\n    # Define and check tail\n    tail_start = len - tail_length + 1  # index of smallest tail value\n    @views tail = sorted_ratios[tail_start:len]\n    check_tail(tail)\n\n    # Get value just before the tail starts:\n    cutoff = sorted_ratios[tail_start - 1]\n    ξ = psis_smooth_tail!(tail, cutoff)\n\n    # truncate at max of raw weights (1 after scaling)\n    clamp!(sorted_ratios, 0, 1)\n    # unsort the ratios to their original position:\n    is_ratios .= @views sorted_ratios[invperm(ordering)]\n\n    return ξ::T\nend\n\n\"\"\"\n    def_tail_length(log_ratios::AbstractVector, r_eff::AbstractFloat) -> tail_len::Integer\n\nDefine the tail length as in Vehtari et al. (2019).\n\"\"\"\nfunction def_tail_length(length::I, r_eff) where {I<:Integer}\n    return I(ceil(min(length / 5, 3 * sqrt(length / r_eff))))\nend\n\n\"\"\"\n    psis_smooth_tail!(tail::AbstractVector{T}, cutoff::T) where {T<:AbstractFloat} -> ξ::T\n\nTakes an *already sorted* vector of observations from the tail and smooths it *in place*  \nwith PSIS before returning shape parameter `ξ`.\n\"\"\"\nfunction psis_smooth_tail!(tail::AbstractVector{T}, cutoff::T) where {T<:AbstractFloat}\n    len = length(tail)\n    @turbo @. tail = tail - cutoff\n\n    # save time not sorting since tail is already sorted\n    ξ, σ = gpdfit(tail)\n    if ξ ≠ Inf\n        @turbo @. tail = gpd_quantile(($(1:len) - 0.5) / len, ξ, σ) + cutoff\n    end\n    return ξ\nend\n\n##########################\n#####  PSIS STRUCTS  #####\n##########################\n\n\"\"\"\n    Psis{V<:AbstractVector{F},I<:Integer} where {F<:AbstractFloat}\n\nA struct containing the results of Pareto-smoothed importance sampling.\n\n# Fields\n- `weights`: A vector of smoothed, truncated, and *normalized* importance sampling weights.\n- `pareto_k`: Estimates of the shape parameter ``k`` of the generalized Pareto distribution.\n- `ess`: Estimated effective sample size for each LOO evaluation.\n- `tail_len`: Vector of tail lengths used for smoothing the generalized Pareto distribution.\n- `dims`: Named tuple of length 2 containing `s` (posterior sample size) and `n` (number of\nobservations).\n\"\"\"\nstruct Psis{\n    F<:AbstractFloat,\n    AF<:AbstractArray{F,3},\n    VF<:AbstractVector{F},\n    I<:Integer,\n    VI<:AbstractVector{I},\n}\n    weights::AF\n    pareto_k::VF\n    ess::VF\n    r_eff::VF\n    tail_len::VI\n    posterior_sample_size::I\n    data_size::I\nend\n\n##########################\n#### HELPER FUNCTIONS ####\n##########################\n\n\"\"\"\nGenerate the relative effective sample size if not provided by the user.\n\"\"\"\nfunction _generate_r_eff(weights, dims, r_eff, source)\n    if isempty(r_eff)\n        if source == \"mcmc\"\n            @info \"Adjusting for autocorrelation. If the posterior samples are not \" *\n                  \"autocorrelated, specify the source of the posterior sample using the \" *\n                  \"keyword argument `source`. MCMC samples are always autocorrelated; VI \" *\n                  \"samples are not.\"\n            return relative_eff(reshape(weights, dims))\n        elseif source ∈ SAMPLE_SOURCES\n            @info \"Samples have not been adjusted for autocorrelation. If the posterior \" *\n                  \"samples are autocorrelated, as in MCMC methods, ESS estimates will be \" *\n                  \"upward-biased, and standard error estimates will be downward-biased. \" *\n                  \"MCMC samples are always autocorrelated; VI samples are not.\"\n            return ones(size(weights, 1))\n        else\n            throw(\n                ArgumentError(\n                    \"$source is not a valid source. Valid sources are $SAMPLE_SOURCES.\"\n                ),\n            )\n            return ones(size(weights, 1))\n        end\n    else\n        return r_eff\n    end\nend\n\n\"\"\"\nMake sure all inputs to `psis` are valid.\n\"\"\"\nfunction check_input_validity_psis(\n    log_ratios::AbstractArray{T,3}, r_eff::AbstractVector{T}\n) where {T<:AbstractFloat}\n    if any(isnan, log_ratios)\n        throw(DomainError(\"Invalid input for `log_ratios` (contains NaN values).\"))\n    elseif any(isinf, log_ratios)\n        throw(DomainError(\"Invalid input for `log_ratios` (contains infinite values).\"))\n    elseif isempty(log_ratios)\n        throw(ArgumentError(\"Invalid input for `log_ratios` (array is empty).\"))\n    elseif any(isnan, r_eff)\n        throw(ArgumentError(\"Invalid input for `r_eff` (contains NaN values).\"))\n    elseif any(isinf, r_eff)\n        throw(DomainError(\"Invalid input for `r_eff` (contains infinite values).\"))\n    elseif isempty(log_ratios)\n        throw(ArgumentError(\"Invalid input for `r_eff` (array is empty).\"))\n    elseif length(r_eff) ≠ size(log_ratios, 1)\n        throw(ArgumentError(\"Size of `r_eff` does not equal the number of data points.\"))\n    end\n    return nothing\nend\n\n\"\"\"\nCheck the tail to make sure a GPD fit is possible.\n\"\"\"\nfunction check_tail(tail::AbstractVector{T}) where {T<:AbstractFloat}\n    if maximum(tail) ≈ minimum(tail)\n        throw(\n            ArgumentError(\n                \"Unable to fit generalized Pareto distribution: all tail values are the\" *\n                \"same. Likely causes are: \\n$LIKELY_ERROR_CAUSES\",\n            ),\n        )\n    elseif length(tail) < MIN_TAIL_LEN\n        throw(\n            ArgumentError(\n                \"Unable to fit generalized Pareto distribution: tail length was too \" *\n                \"short. Likely causese are: \\n$LIKELY_ERROR_CAUSES\"\n            ),\n        )\n    end\n    return nothing\nend\n\n\n\"\"\"\nAssume that all objects belong to a single chain if chain index is missing. Warn user.\n\"\"\"\nfunction _assume_one_chain(log_ratios)\n    @info \"Chain information was not provided; \" *\n          \"all samples are assumed to be drawn from a single chain.\"\n    return ones(length(log_ratios))\nend\n\n\n\"\"\"\nConvert a matrix+chain_index representation to a 3d array representation to pass it off to \nthe method for arrays.\n\"\"\"\nfunction _convert_to_array(log_ratios::AbstractMatrix, chain_index::AbstractVector)\n    indices = unique(chain_index)\n    biggest_idx = maximum(indices)\n    dims = size(log_ratios)\n    if dims[2] ≠ length(chain_index)\n        throw(ArgumentError(\"Some entries do not have a chain index.\"))\n    elseif !issetequal(indices, 1:biggest_idx)\n        throw(\n            ArgumentError(\n                \"Indices must be numbered from 1 through the total number of chains.\"\n            ),\n        )\n    else\n        # Check how many elements are in each chain, assign to \"counts\"\n        counts = count.(eachslice(chain_index .== indices'; dims=2))\n        # check if all inputs are the same length\n        if !all(==(counts[1]), counts)\n            throw(ArgumentError(\"All chains must be of equal length.\"))\n        end\n    end\n    new_ratios = similar(log_ratios, dims[1], dims[2] ÷ biggest_idx, biggest_idx)\n    for i in 1:biggest_idx\n        new_ratios[:, :, i] .= log_ratios[:, chain_index .== i]\n    end\n    return new_ratios\nend"
        }
    ]
}