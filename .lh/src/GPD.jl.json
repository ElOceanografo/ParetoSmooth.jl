{
    "sourceFile": "src/GPD.jl",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 20,
            "patches": [
                {
                    "date": 1626310029646,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1626314400489,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,11 +1,11 @@\n using LinearAlgebra\n using LoopVectorization\n using Statistics\n+using TensorOperations\n using Tullio\n \n \n-\n \"\"\"\n     gpdfit(\n         sample::AbstractVector{T<:AbstractFloat}; \n         wip::Bool=true, \n"
                },
                {
                    "date": 1626314494491,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,17 +54,17 @@\n     θ_hats = similar(sample, grid_size)\n     ξ_hats = similar(sample, grid_size)\n     @turbo @. θ_hats =\n         inv(sample[len]) + (1 - sqrt((grid_size+1) / $(1:grid_size))) / prior / quartile\n-    @tullio threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n+    @tullio avx=false tensor=true threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n     log_like = similar(ξ_hats)\n     # Calculate profile log-likelihood at each estimate:\n     @turbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n     # Calculate weights from log-likelihood:\n     weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n-    @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n+    @tullio avx=false tensor=true threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n-    @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n+    @tullio avx=false tensor=true threads=false θ_hat := weights[x] * θ_hats[x]\n \n     ξ::T = calc_ξ(sample, θ_hat)\n     σ::T = -ξ / θ_hat\n \n"
                },
                {
                    "date": 1626314557716,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,11 +1,11 @@\n using LinearAlgebra\n using LoopVectorization\n using Statistics\n-using TensorOperations\n using Tullio\n \n \n+\n \"\"\"\n     gpdfit(\n         sample::AbstractVector{T<:AbstractFloat}; \n         wip::Bool=true, \n@@ -54,17 +54,17 @@\n     θ_hats = similar(sample, grid_size)\n     ξ_hats = similar(sample, grid_size)\n     @turbo @. θ_hats =\n         inv(sample[len]) + (1 - sqrt((grid_size+1) / $(1:grid_size))) / prior / quartile\n-    @tullio avx=false tensor=true threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n+    @tullio threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n     log_like = similar(ξ_hats)\n     # Calculate profile log-likelihood at each estimate:\n     @turbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n     # Calculate weights from log-likelihood:\n     weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n-    @tullio avx=false tensor=true threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n+    @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n-    @tullio avx=false tensor=true threads=false θ_hat := weights[x] * θ_hats[x]\n+    @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n \n     ξ::T = calc_ξ(sample, θ_hat)\n     σ::T = -ξ / θ_hat\n \n"
                },
                {
                    "date": 1626314693762,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,9 +3,8 @@\n using Statistics\n using Tullio\n \n \n-\n \"\"\"\n     gpdfit(\n         sample::AbstractVector{T<:AbstractFloat}; \n         wip::Bool=true, \n@@ -52,19 +51,19 @@\n \n     # build pointwise estimates of ξ and θ at each grid point\n     θ_hats = similar(sample, grid_size)\n     ξ_hats = similar(sample, grid_size)\n-    @turbo @. θ_hats =\n+    @tturbo @. θ_hats =\n         inv(sample[len]) + (1 - sqrt((grid_size+1) / $(1:grid_size))) / prior / quartile\n-    @tullio threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n+    @tullio ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n     log_like = similar(ξ_hats)\n     # Calculate profile log-likelihood at each estimate:\n-    @turbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n+    @tturbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n     # Calculate weights from log-likelihood:\n     weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n-    @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n+    @tullio weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n-    @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n+    @tullio θ_hat := weights[x] * θ_hats[x]\n \n     ξ::T = calc_ξ(sample, θ_hat)\n     σ::T = -ξ / θ_hat\n \n@@ -103,9 +102,9 @@\n Calculate ξ, the parameter for the GPD.\n \"\"\"\n function calc_ξ(sample::AbstractVector{T}, θ_hat::T) where {T<:AbstractFloat}\n     ξ = zero(T)\n-    @turbo for i in eachindex(sample)\n+    @tturbo for i in eachindex(sample)\n         ξ += log1p(-θ_hat * sample[i]) / length(sample)\n     end\n     return ξ::T\n end\n"
                },
                {
                    "date": 1626314740174,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,19 +51,19 @@\n \n     # build pointwise estimates of ξ and θ at each grid point\n     θ_hats = similar(sample, grid_size)\n     ξ_hats = similar(sample, grid_size)\n-    @tturbo @. θ_hats =\n+    @turbo @. θ_hats =\n         inv(sample[len]) + (1 - sqrt((grid_size+1) / $(1:grid_size))) / prior / quartile\n-    @tullio ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n+    @tullio threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n     log_like = similar(ξ_hats)\n     # Calculate profile log-likelihood at each estimate:\n-    @tturbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n+    @turbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n     # Calculate weights from log-likelihood:\n     weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n-    @tullio weights[y] = exp(log_like[x] - log_like[y]) |> inv\n+    @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n-    @tullio θ_hat := weights[x] * θ_hats[x]\n+    @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n \n     ξ::T = calc_ξ(sample, θ_hat)\n     σ::T = -ξ / θ_hat\n \n@@ -102,9 +102,9 @@\n Calculate ξ, the parameter for the GPD.\n \"\"\"\n function calc_ξ(sample::AbstractVector{T}, θ_hat::T) where {T<:AbstractFloat}\n     ξ = zero(T)\n-    @tturbo for i in eachindex(sample)\n+    @turbo for i in eachindex(sample)\n         ξ += log1p(-θ_hat * sample[i]) / length(sample)\n     end\n     return ξ::T\n end\n"
                },
                {
                    "date": 1626362460303,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -44,8 +44,9 @@\n \n \n     prior = 3\n     grid_size = min_grid_pts + isqrt(len) # isqrt = floor sqrt\n+    grid_size = grid_size - (grid_size % 32) # multiples of 32 speed up calcs\n     n_0 = 10  # determines how strongly to nudge ξ towards .5\n     quartile::T = sample[(len+2)÷4]\n \n \n"
                },
                {
                    "date": 1626362509519,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -44,9 +44,8 @@\n \n \n     prior = 3\n     grid_size = min_grid_pts + isqrt(len) # isqrt = floor sqrt\n-    grid_size = grid_size - (grid_size % 32) # multiples of 32 speed up calcs\n     n_0 = 10  # determines how strongly to nudge ξ towards .5\n     quartile::T = sample[(len+2)÷4]\n \n \n"
                },
                {
                    "date": 1626484293993,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,9 +33,9 @@\n     sample::AbstractVector{T};\n     wip::Bool=true,\n     min_grid_pts::Integer=30,\n     sort_sample::Bool=false,\n-) where {T<:AbstractFloat}\n+) where {T <: AbstractFloat}\n \n     len = length(sample)\n     # sample must be sorted, but we can skip if sample is already sorted\n     if sort_sample\n@@ -52,18 +52,18 @@\n     # build pointwise estimates of ξ and θ at each grid point\n     θ_hats = similar(sample, grid_size)\n     ξ_hats = similar(sample, grid_size)\n     @turbo @. θ_hats =\n-        inv(sample[len]) + (1 - sqrt((grid_size+1) / $(1:grid_size))) / prior / quartile\n-    @tullio threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n+        inv(sample[len]) + (1 - sqrt((grid_size + 1) / $(1:grid_size))) / prior / quartile\n+    @tullio threads = false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n     log_like = similar(ξ_hats)\n     # Calculate profile log-likelihood at each estimate:\n     @turbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n     # Calculate weights from log-likelihood:\n     weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n-    @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n+    @tullio threads = false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n-    @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n+    @tullio threads = false θ_hat := weights[x] * θ_hats[x]\n \n     ξ::T = calc_ξ(sample, θ_hat)\n     σ::T = -ξ / θ_hat\n \n@@ -90,9 +90,9 @@\n # Returns\n \n A quantile of the Generalized Pareto Distribution.\n \"\"\"\n-function gpd_quantile(p, k::T, sigma::T) where {T<:AbstractFloat}\n+function gpd_quantile(p, k::T, sigma::T) where {T <: AbstractFloat}\n     return sigma * expm1(-k * log1p(-p)) / k\n end\n \n \n@@ -100,9 +100,9 @@\n     calc_ξ(sample, θ_hat)\n \n Calculate ξ, the parameter for the GPD.\n \"\"\"\n-function calc_ξ(sample::AbstractVector{T}, θ_hat::T) where {T<:AbstractFloat}\n+function calc_ξ(sample::AbstractVector{T}, θ_hat::T) where {T <: AbstractFloat}\n     ξ = zero(T)\n     @turbo for i in eachindex(sample)\n         ξ += log1p(-θ_hat * sample[i]) / length(sample)\n     end\n"
                },
                {
                    "date": 1626484439615,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -52,18 +52,18 @@\n     # build pointwise estimates of ξ and θ at each grid point\n     θ_hats = similar(sample, grid_size)\n     ξ_hats = similar(sample, grid_size)\n     @turbo @. θ_hats =\n-        inv(sample[len]) + (1 - sqrt((grid_size + 1) / $(1:grid_size))) / prior / quartile\n-    @tullio threads = false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n+        inv(sample[len]) + (1 - sqrt((grid_size+1) / $(1:grid_size))) / prior / quartile\n+    @tullio threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n     log_like = similar(ξ_hats)\n     # Calculate profile log-likelihood at each estimate:\n     @turbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n     # Calculate weights from log-likelihood:\n     weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n-    @tullio threads = false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n+    @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n-    @tullio threads = false θ_hat := weights[x] * θ_hats[x]\n+    @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n \n     ξ::T = calc_ξ(sample, θ_hat)\n     σ::T = -ξ / θ_hat\n \n"
                },
                {
                    "date": 1626484457349,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -101,11 +101,11 @@\n \n Calculate ξ, the parameter for the GPD.\n \"\"\"\n function calc_ξ(sample::AbstractVector{T}, θ_hat::T) where {T <: AbstractFloat}\n-    ξ = zero(T)\n+    ξ::T = zero(T)\n     @turbo for i in eachindex(sample)\n         ξ += log1p(-θ_hat * sample[i]) / length(sample)\n     end\n-    return ξ::T\n+    return ξ\n end\n \n"
                },
                {
                    "date": 1626484527691,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,8 +62,9 @@\n     weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n     @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n     @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n+    @tullio threads=false ξ := log1p(-θ_hat * sample[i]) |> _ / len\n \n     ξ::T = calc_ξ(sample, θ_hat)\n     σ::T = -ξ / θ_hat\n \n@@ -94,18 +95,4 @@\n function gpd_quantile(p, k::T, sigma::T) where {T <: AbstractFloat}\n     return sigma * expm1(-k * log1p(-p)) / k\n end\n \n-\n-\"\"\"\n-    calc_ξ(sample, θ_hat)\n-\n-Calculate ξ, the parameter for the GPD.\n-\"\"\"\n-function calc_ξ(sample::AbstractVector{T}, θ_hat::T) where {T <: AbstractFloat}\n-    ξ::T = zero(T)\n-    @turbo for i in eachindex(sample)\n-        ξ += log1p(-θ_hat * sample[i]) / length(sample)\n-    end\n-    return ξ\n-end\n-\n"
                },
                {
                    "date": 1626486963522,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,9 +9,9 @@\n         sample::AbstractVector{T<:AbstractFloat}; \n         wip::Bool=true, \n         min_grid_pts::Integer=30, \n         sort_sample::Bool=false\n-        ) -> (ξ::T, σ::T)\n+    ) -> (ξ::T, σ::T)\n \n Return a named list of estimates for the parameters ξ (shape) and σ (scale) of the\n generalized Pareto distribution (GPD), assuming the location parameter is 0.\n \n"
                },
                {
                    "date": 1626487070812,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,9 +64,8 @@\n     # Take weighted mean:\n     @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n     @tullio threads=false ξ := log1p(-θ_hat * sample[i]) |> _ / len\n \n-    ξ::T = calc_ξ(sample, θ_hat)\n     σ::T = -ξ / θ_hat\n \n     # Drag towards .5 to reduce variance for small len\n     if wip\n"
                },
                {
                    "date": 1626487134955,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,10 +62,10 @@\n     weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n     @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n     @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n-    @tullio threads=false ξ := log1p(-θ_hat * sample[i]) |> _ / len\n-\n+    @tullio threads=false ξ := log1p(-θ_hat * sample[i])\n+    ξ /= len\n     σ::T = -ξ / θ_hat\n \n     # Drag towards .5 to reduce variance for small len\n     if wip\n"
                },
                {
                    "date": 1626728670823,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,9 +26,9 @@\n \n # Note\n \n Estimation method taken from Zhang, J. and Stephens, M.A. (2009). The parameter ξ is the\n-negative of \\$k\\$.\n+negative of k.\n \"\"\"\n function gpdfit(\n     sample::AbstractVector{T};\n     wip::Bool=true,\n"
                },
                {
                    "date": 1626740644062,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,25 +42,24 @@\n         sample = sort(sample; alg=QuickSort)\n     end\n \n \n-    prior = 3\n-    grid_size = min_grid_pts + isqrt(len) # isqrt = floor sqrt\n+    grid_size = min_grid_pts + isqrt(len)  # isqrt = floor sqrt\n     n_0 = 10  # determines how strongly to nudge ξ towards .5\n-    quartile::T = sample[(len+2)÷4]\n+    x_star::T = inv(3 * sample[(len+2)÷4])  # magic number. ¯\\_(ツ)_/¯\n \n \n     # build pointwise estimates of ξ and θ at each grid point\n     θ_hats = similar(sample, grid_size)\n     ξ_hats = similar(sample, grid_size)\n-    @turbo @. θ_hats =\n-        inv(sample[len]) + (1 - sqrt((grid_size+1) / $(1:grid_size))) / prior / quartile\n-    @tullio threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n-    log_like = similar(ξ_hats)\n+    invmax = inv(sample[len])\n+    @tullio threads=false θ_hats[i] = invmax + (1 - sqrt((grid_size+1) / i)) * x_star\n+    @tullio threads=false ξ_hats[i] = log1p(-θ_hats[i] * sample[j]) |> _ / len\n+    log_like = ξ_hats # Reuse preallocated array (which is no longer in use)\n     # Calculate profile log-likelihood at each estimate:\n-    @turbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n+    @tullio log_like[i] = len * (log(-θ_hats[i] / ξ_hats[i]) - ξ_hats[i] - 1)\n     # Calculate weights from log-likelihood:\n-    weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n+    weights = ξ_hats  # Reuse preallocated array\n     @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n     @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n     @tullio threads=false ξ := log1p(-θ_hat * sample[i])\n"
                },
                {
                    "date": 1626749759953,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,9 @@\n     @tullio threads=false θ_hats[i] = invmax + (1 - sqrt((grid_size+1) / i)) * x_star\n     @tullio threads=false ξ_hats[i] = log1p(-θ_hats[i] * sample[j]) |> _ / len\n     log_like = ξ_hats # Reuse preallocated array (which is no longer in use)\n     # Calculate profile log-likelihood at each estimate:\n-    @tullio log_like[i] = len * (log(-θ_hats[i] / ξ_hats[i]) - ξ_hats[i] - 1)\n+    @tullio threads=false log_like[i] = len * (log(-θ_hats[i] / ξ_hats[i]) - ξ_hats[i] - 1)\n     # Calculate weights from log-likelihood:\n     weights = ξ_hats  # Reuse preallocated array\n     @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n     # Take weighted mean:\n"
                },
                {
                    "date": 1626749940388,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n     ξ_hats = similar(sample, grid_size)\n     invmax = inv(sample[len])\n     @tullio threads=false θ_hats[i] = invmax + (1 - sqrt((grid_size+1) / i)) * x_star\n     @tullio threads=false ξ_hats[i] = log1p(-θ_hats[i] * sample[j]) |> _ / len\n-    log_like = ξ_hats # Reuse preallocated array (which is no longer in use)\n+    log_like = similar(ξ_hats) # Reuse preallocated array (which is no longer in use)\n     # Calculate profile log-likelihood at each estimate:\n     @tullio threads=false log_like[i] = len * (log(-θ_hats[i] / ξ_hats[i]) - ξ_hats[i] - 1)\n     # Calculate weights from log-likelihood:\n     weights = ξ_hats  # Reuse preallocated array\n"
                },
                {
                    "date": 1626750106821,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,9 +67,9 @@\n     σ::T = -ξ / θ_hat\n \n     # Drag towards .5 to reduce variance for small len\n     if wip\n-        ξ = (ξ * len + 0.5 * n_0) / (len + n_0)\n+        @fastmath ξ = (ξ * len + 0.5 * n_0) / (len + n_0)\n     end\n \n     return ξ::T, σ::T\n \n"
                },
                {
                    "date": 1626750148008,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -43,8 +43,9 @@\n     end\n \n \n     grid_size = min_grid_pts + isqrt(len)  # isqrt = floor sqrt\n+    grid_size = grid_size - (grid_size % 4)  # multiples of 4 easier to vectorize\n     n_0 = 10  # determines how strongly to nudge ξ towards .5\n     x_star::T = inv(3 * sample[(len+2)÷4])  # magic number. ¯\\_(ツ)_/¯\n \n \n"
                }
            ],
            "date": 1626310029646,
            "name": "Commit-0",
            "content": "using LinearAlgebra\nusing LoopVectorization\nusing Statistics\nusing Tullio\n\n\n\n\"\"\"\n    gpdfit(\n        sample::AbstractVector{T<:AbstractFloat}; \n        wip::Bool=true, \n        min_grid_pts::Integer=30, \n        sort_sample::Bool=false\n        ) -> (ξ::T, σ::T)\n\nReturn a named list of estimates for the parameters ξ (shape) and σ (scale) of the\ngeneralized Pareto distribution (GPD), assuming the location parameter is 0.\n\n# Arguments\n\n  - `sample::AbstractVector`: A numeric vector. The sample from which to estimate\n    the parameters.\n  - `wip::Bool = true`: Logical indicating whether to adjust ξ based on a weakly informative\n    Gaussian prior centered on 0.5. Defaults to `true`.\n  - `min_grid_pts::Integer = 30`: The minimum number of grid points used in the fitting\n    algorithm. The actual number used is `min_grid_pts + ⌊sqrt(length(sample))⌋`.\n\n# Note\n\nEstimation method taken from Zhang, J. and Stephens, M.A. (2009). The parameter ξ is the\nnegative of \\$k\\$.\n\"\"\"\nfunction gpdfit(\n    sample::AbstractVector{T};\n    wip::Bool=true,\n    min_grid_pts::Integer=30,\n    sort_sample::Bool=false,\n) where {T<:AbstractFloat}\n\n    len = length(sample)\n    # sample must be sorted, but we can skip if sample is already sorted\n    if sort_sample\n        sample = sort(sample; alg=QuickSort)\n    end\n\n\n    prior = 3\n    grid_size = min_grid_pts + isqrt(len) # isqrt = floor sqrt\n    n_0 = 10  # determines how strongly to nudge ξ towards .5\n    quartile::T = sample[(len+2)÷4]\n\n\n    # build pointwise estimates of ξ and θ at each grid point\n    θ_hats = similar(sample, grid_size)\n    ξ_hats = similar(sample, grid_size)\n    @turbo @. θ_hats =\n        inv(sample[len]) + (1 - sqrt((grid_size+1) / $(1:grid_size))) / prior / quartile\n    @tullio threads=false ξ_hats[x] := log1p(-θ_hats[x] * sample[y]) |> _ / len\n    log_like = similar(ξ_hats)\n    # Calculate profile log-likelihood at each estimate:\n    @turbo @. log_like = len * (log(-θ_hats / ξ_hats) - ξ_hats - 1)\n    # Calculate weights from log-likelihood:\n    weights = ξ_hats  # Reuse preallocated array (which is no longer in use)\n    @tullio threads=false weights[y] = exp(log_like[x] - log_like[y]) |> inv\n    # Take weighted mean:\n    @tullio threads=false θ_hat := weights[x] * θ_hats[x]\n\n    ξ::T = calc_ξ(sample, θ_hat)\n    σ::T = -ξ / θ_hat\n\n    # Drag towards .5 to reduce variance for small len\n    if wip\n        ξ = (ξ * len + 0.5 * n_0) / (len + n_0)\n    end\n\n    return ξ::T, σ::T\n\nend\n\n\"\"\"\n    gpd_quantile(p::T, k::T, sigma::T) where {T<:AbstractFloat} -> T\n\nCompute the `p` quantile of the Generalized Pareto Distribution (GPD).\n\n# Arguments\n\n  - `p`: A scalar between 0 and 1.\n  - `ξ`: A scalar shape parameter.\n  - `σ`: A scalar scale parameter.\n\n# Returns\n\nA quantile of the Generalized Pareto Distribution.\n\"\"\"\nfunction gpd_quantile(p, k::T, sigma::T) where {T<:AbstractFloat}\n    return sigma * expm1(-k * log1p(-p)) / k\nend\n\n\n\"\"\"\n    calc_ξ(sample, θ_hat)\n\nCalculate ξ, the parameter for the GPD.\n\"\"\"\nfunction calc_ξ(sample::AbstractVector{T}, θ_hat::T) where {T<:AbstractFloat}\n    ξ = zero(T)\n    @turbo for i in eachindex(sample)\n        ξ += log1p(-θ_hat * sample[i]) / length(sample)\n    end\n    return ξ::T\nend\n\n"
        }
    ]
}